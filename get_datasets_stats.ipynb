{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scripts.data_analysis import figure_creation\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insurance.csv', 'melb_data.csv', 'SeoulBikeData.csv', 'Sleep_Efficiency.csv', 'uci_1.csv', 'winequalityN.csv']\n",
      "['insurance', 'melb_data', 'SeoulBikeData', 'Sleep_Efficiency', 'uci_1', 'winequalityN']\n",
      "['Insurance', 'Melbourne Housing', 'Seoul Bike', 'Sleep Efficiency', 'Abalone', 'Wine Quality']\n"
     ]
    }
   ],
   "source": [
    "# get names of all csv files in data/preprocessed_datasets\n",
    "datasets = [f for f in os.listdir('data/preprocessed_datasets') if f.endswith('.csv')]\n",
    "print(datasets)\n",
    "names = [f.split('.')[0] for f in datasets]\n",
    "print(names)\n",
    "\n",
    "\n",
    "\n",
    "names = [name_to_pretty_name(name) for name in names]\n",
    "print(names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating distributions for Insurance dataset\n",
      "Creating distributions for Melbourne Housing dataset\n",
      "Creating distributions for Seoul Bike dataset\n",
      "Creating distributions for Sleep Efficiency dataset\n",
      "Creating distributions for Abalone dataset\n",
      "Creating distributions for Wine Quality dataset\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in zip(datasets, names):\n",
    "    print(f'Creating distributions for {name} dataset')\n",
    "    try:\n",
    "        df = pd.read_csv(f'data/preprocessed_datasets/{dataset}', encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(f'data/preprocessed_datasets/{dataset}', encoding='ISO-8859-1')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(f'data/preprocessed_datasets/{dataset}', encoding='cp1252')\n",
    "\n",
    "    figure_creation.create_distributions(name,df,  processed=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insurance.csv', 'melb_data.csv', 'SeoulBikeData.csv', 'Sleep_Efficiency.csv', 'uci_1.csv', 'winequalityN.csv']\n",
      "['insurance', 'melb_data', 'SeoulBikeData', 'Sleep_Efficiency', 'uci_1', 'winequalityN']\n",
      "['Insurance', 'Melbourne Housing', 'Seoul Bike', 'Sleep Efficiency', 'Abalone', 'Wine Quality']\n"
     ]
    }
   ],
   "source": [
    "# get names of all csv files in data/preprocessed_datasets\n",
    "datasets = [f for f in os.listdir('data/processed_datasets') if f.endswith('.csv')]\n",
    "print(datasets)\n",
    "names = [f.split('.')[0] for f in datasets]\n",
    "print(names)\n",
    "\n",
    "name_to_pretty_name = {\n",
    "    'insurance': 'Insurance',\n",
    "    'melb_data': 'Melbourne Housing',\n",
    "    'SeoulBikeData': 'Seoul Bike',\n",
    "    'Sleep_Efficiency': 'Sleep Efficiency',\n",
    "    'uci_1': 'Abalone',\n",
    "    'winequalityN': 'Wine Quality',\n",
    "}\n",
    "\n",
    "names = [name_to_pretty_name[name] for name in names]\n",
    "print(names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating plots for Insurance dataset\n",
      "Creating plots for Melbourne Housing dataset\n",
      "Creating plots for Seoul Bike dataset\n",
      "Creating plots for Sleep Efficiency dataset\n",
      "Creating plots for Abalone dataset\n",
      "Creating plots for Wine Quality dataset\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in zip(datasets, names):\n",
    "    print(f'Creating plots for {name} dataset')\n",
    "    try:\n",
    "        df = pd.read_csv(f'data/processed_datasets/{dataset}', encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(f'data/processed_datasets/{dataset}', encoding='ISO-8859-1')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(f'data/processed_datasets/{dataset}', encoding='cp1252')\n",
    "\n",
    "    figure_creation.create_distributions(name,df, processed=True)\n",
    "    figure_creation.create_correlation_heatmap(name,df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
